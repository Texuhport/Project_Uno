{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b902c28-4f2c-43c1-b73d-173719cf79b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your choice of 'Trade Term' will define the timeframe with which we will analyze stock returns\n",
      "Select a trade term that matches your current investment goals for collecting returns from stock investments\n",
      "\n",
      "Choose a Trade Term From These Options:\n",
      "1. 1Yrs (1 Year)\n",
      "2. 5Yrs (5 Years)\n",
      "3. 10Yrs (10 Years)\n",
      "4. 15Yrs (15 Years)\n",
      "5. 7Dys (7 Days)\n",
      "6. 21Dys (21 Days)\n",
      "7. 40Dys (40 Days)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your trade term 15Yrs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Your choice of 'Risk Threshold' will define how risky and volatile the stocks in the final portfolio will be\n",
      "Select a risk threshold that matches your comfort levels when it comes to risk\n",
      "\n",
      "Choose a Risk Threshold:\n",
      "1. high\n",
      "2. mid\n",
      "3. low\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your risk threshold low\n"
     ]
    }
   ],
   "source": [
    "#USER INPUT\n",
    "\n",
    "#TRADE TERM\n",
    "print(\"Your choice of 'Trade Term' will define the timeframe with which we will analyze stock returns\")\n",
    "print(\"Select a trade term that matches your current investment goals for collecting returns from stock investments\")\n",
    "print(\"\")\n",
    "print(\"Choose a Trade Term From These Options:\")\n",
    "print(\"1. 1Yrs (1 Year)\")\n",
    "print(\"2. 5Yrs (5 Years)\")\n",
    "print(\"3. 10Yrs (10 Years)\")\n",
    "print(\"4. 15Yrs (15 Years)\")\n",
    "print(\"5. 7Dys (7 Days)\")\n",
    "print(\"6. 21Dys (21 Days)\")\n",
    "print(\"7. 40Dys (40 Days)\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "user_trade_term= input(\"Enter your trade term\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "#RISK THRESHOLD\n",
    "print(\"Your choice of 'Risk Threshold' will define how risky and volatile the stocks in the final portfolio will be\")\n",
    "print(\"Select a risk threshold that matches your comfort levels when it comes to risk\")\n",
    "print(\"\")\n",
    "print(\"Choose a Risk Threshold:\")\n",
    "print(\"1. high\")\n",
    "print(\"2. mid\")\n",
    "print(\"3. low\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "user_risk= input(\"Enter your risk threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5ac65b-385c-4888-a976-5cc9b5682cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pytz\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481b6d77-f976-47d1-963f-315f3c2190f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define user variables | Personalize the final results\n",
    "user_trade_term = '15Yrs'\n",
    "user_risk= 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268cd8cd-d21f-425e-945c-b668acef5302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oluwa\\AppData\\Local\\Temp\\ipykernel_5016\\678915812.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Smaller_Dataframe['Date'] = Smaller_Dataframe['Date'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#Create Term Splitting Logic\n",
    "if user_trade_term == '15Yrs':\n",
    "    trade_term = 15\n",
    "    \n",
    "elif user_trade_term == '10Yrs':\n",
    "    trade_term = 10\n",
    "    \n",
    "elif user_trade_term == '5Yrs':\n",
    "    trade_term = 5\n",
    "\n",
    "elif user_trade_term == '1Yrs':\n",
    "    trade_term = 1\n",
    "\n",
    "elif user_trade_term == '21Dys':\n",
    "    trade_term = 0.0575342\n",
    "\n",
    "elif user_trade_term == '7Dys':\n",
    "    trade_term = 0.0191781\n",
    "\n",
    "elif user_trade_term == '40Dys':\n",
    "    trade_term = 0.109589\n",
    "\n",
    "else:\n",
    "    print(\"Invalid user_trade_term value\")\n",
    "    \n",
    "# Read in the stocks dataset to clean it\n",
    "World_Stocks = pd.read_csv(Path(r\"C:\\Users\\Oluwa\\GITHUB\\Bootcamp\\ASSIGNMENTS\\Project_Uno\\Resources\\World-Stock-Prices-Dataset.csv\"))\n",
    "\n",
    "#Cut dataset down to US stocks only\n",
    "World_Stocks = World_Stocks[World_Stocks['Country'] == 'usa']\n",
    "\n",
    "#Read in the bond yields dataset for later\n",
    "Bond_yields = pd.read_csv(Path(r\"C:\\Users\\Oluwa\\GITHUB\\Bootcamp\\ASSIGNMENTS\\Project_Uno\\Resources\\bond_yields_all.csv\"))\n",
    "                         \n",
    "# Specify the format of the 'Date' column and save it as a variable\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'\n",
    "\n",
    "# Use the variable to reformat the column using a universal timezone and handle errors\n",
    "try:\n",
    "    World_Stocks['Date'] = pd.to_datetime(World_Stocks['Date'], format=date_format, utc=True, errors='coerce')\n",
    "#Use the except functionality to print an error if this doesnt work\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while parsing datetime values: {e}\")\n",
    "\n",
    "#Make sure Bond_yields has the same format\n",
    "Bond_yields['Date'] = pd.to_datetime(Bond_yields['date'], format=date_format, utc=True, errors='coerce')\n",
    "\n",
    "# Set 'Date' format to match 'World_Stocks' and fill missing values with 0\n",
    "Bond_yields['Date'] = Bond_yields['Date'].dt.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "Bond_yields.fillna(0, inplace=True)\n",
    "\n",
    "Yr5_Bond=Bond_yields.drop(columns='date') #cleanup\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "Yr5_Bond['Date'] = pd.to_datetime(Yr5_Bond['Date'], format='%Y-%m-%d %H:%M:%S%z', errors='coerce')\n",
    "Yr5_Bond.fillna(0, inplace=True)\n",
    "\n",
    "# Make sure all stock data calls cut off at the same datetime by making their timezones match\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * trade_term)\n",
    "\n",
    "# Convert cutoff_date to a string with timezone information\n",
    "cutoff_date_str = cutoff_date.strftime(date_format)\n",
    "\n",
    "# Manually add UTC offset to the string (+00:00 for UTC) | Ensure that all dates in the string match the UTC format\n",
    "cutoff_date_str += '+00:00'\n",
    "\n",
    "# Parse the string back to a datetime64 object with the same timezone\n",
    "try:\n",
    "    cutoff_date = pd.to_datetime(cutoff_date_str, format=date_format, utc=True)\n",
    "#Use the except functionality to print an error if this doesnt work\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while parsing the cutoff_date: {e}\")\n",
    "\n",
    "#Replace the timezone information with the one from the first date of the dataframe. Normalizing all the date data.\n",
    "cutoff_date = cutoff_date.replace(tzinfo=World_Stocks['Date'].iloc[0].tzinfo)\n",
    "\n",
    "# Create a new dataframe variable with only the cells that are after the cut off date\n",
    "Smaller_Dataframe = World_Stocks[World_Stocks['Date'] >= cutoff_date]\n",
    "\n",
    "# Convert the 'Date' column in 'Yr5_Bond' to string format\n",
    "Yr5_Bond['Date'] = Yr5_Bond['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Convert the 'Date' column in Smaller_Dataframe to string format\n",
    "Smaller_Dataframe['Date'] = Smaller_Dataframe['Date'].astype(str)\n",
    "\n",
    "# Extract the first 10 characters from the 'Date' column in 'Smaller_Dataframe'\n",
    "matching_dates = Smaller_Dataframe['Date'].str[:10].unique()\n",
    "\n",
    "# Filter 'Yr5_Bond' based on matching dates\n",
    "Bond_yields_filtered = Yr5_Bond[Yr5_Bond['Date'].str[:10].isin(matching_dates)]\n",
    "\n",
    "# Convert 'Date' column in 'Yr5_Bond' back to the original datetime format\n",
    "Yr5_Bond['Date'] = pd.to_datetime(Yr5_Bond['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert 'Date' column in 'Bond_yields_filtered' back to the original datetime format\n",
    "Bond_yields_filtered['Date'] = pd.to_datetime(Bond_yields_filtered['Date'], format='%Y-%m-%d')\n",
    "\n",
    "#For some reason I couldnt organize the dataframe unless I explicitly copied it. Tried to just make it a variable\n",
    "Calculations_df = Smaller_Dataframe.copy()\n",
    "\n",
    "#Sort the dataframe and clean the data\n",
    "Calculations_df.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "Useless_Columns=['Dividends', 'Stock Splits']\n",
    "Calculations_df.drop(columns=Useless_Columns)\n",
    "Calculations_df.dropna()\n",
    "Compared_Calcs= Calculations_df.groupby(['Date', 'Ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76324490-1724-40b8-8b9d-0224fa82512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for S&P 50 from Yahoo\n",
    "ticker_symbols = '^GSPC'\n",
    "\n",
    "#Set variables for later\n",
    "end_date = datetime(2023, 9, 20)\n",
    "end_date = end_date.replace(tzinfo=pytz.UTC)\n",
    "start_date = end_date - timedelta(days=365 * trade_term)\n",
    "SPData=pd.DataFrame()\n",
    "\n",
    "# Fetch historical data from Yahoo Finance\n",
    "company = yf.Ticker(ticker_symbols)\n",
    "historical_data = company.history(period=\"max\")\n",
    "\n",
    "# Filter data for the specified date range (5 years from the end of September)\n",
    "historical_data = historical_data[(historical_data.index >= start_date) & (historical_data.index <= end_date)]\n",
    "\n",
    "# Reset the index to make the date a column\n",
    "historical_data.reset_index(inplace=True)\n",
    "\n",
    "historical_data['Ticker'] = ticker_symbols\n",
    "\n",
    "# Create a new DataFrame by concatenating filtered data\n",
    "SPData = pd.concat([SPData, historical_data])\n",
    "\n",
    "# Drop columns from the new DataFrame\n",
    "SPData = SPData.drop(columns=Useless_Columns)\n",
    "\n",
    "# Add new columns\n",
    "SPData['Brand_Name'] = 'SP500'\n",
    "SPData['Industry_Tag'] = 'Market Reference'\n",
    "SPData['Country'] = 'Global'\n",
    "\n",
    "# Drop rows with missing values (if needed)\n",
    "SPData = SPData.dropna()\n",
    "\n",
    "# Sort the DataFrame\n",
    "SPData.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "# Initialize an empty DataFrameand list to store Beta values\n",
    "beta_df = pd.DataFrame(columns=['Ticker', 'Beta'])\n",
    "beta_data=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c104b596-9eb0-4b4f-b991-a67fff41bab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate daily returns using the Open and Close columns\n",
    "Calculations_df['Daily_Return'] = Calculations_df['Close'].pct_change() * 100\n",
    "SPData['SP500_Daily_Return'] = SPData['Close'].pct_change() * 100\n",
    "\n",
    "\n",
    "# Create a new DataFrame for Compared_Calcs with 'Daily_Return' values\n",
    "Compared_Calcs = Calculations_df[['Ticker', 'Daily_Return', 'Date']].copy()\n",
    "\n",
    "# Check for missing values in 'Daily_Return' column of Compared_Calcs\n",
    "missing_values = Compared_Calcs['Daily_Return'].isna().sum()\n",
    "\n",
    "# Handle missing values (e.g., fill or drop them)\n",
    "if missing_values > 0:\n",
    "    Compared_Calcs['Daily_Return'].fillna(0, inplace=True)\n",
    "\n",
    "#Calculate cumulative daily returns for each Ticker\n",
    "Compared_Calcs['Cumulative_Return'] = (1 + Compared_Calcs['Daily_Return']).groupby(Compared_Calcs['Ticker']).cumprod()\n",
    "\n",
    "#Calculate the average annualized yield\n",
    "days_per_year = 252*trade_term  \n",
    "Compared_Calcs['Yield'] = (Compared_Calcs['Cumulative_Return'] ** (1 / days_per_year) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fc6342-0013-449e-8de2-4f85c3541ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Volatility\n",
    "stock_vol = Calculations_df.groupby('Ticker')['Daily_Return'].std()\n",
    "\n",
    "# Calculate Value at Risk on each section grouped by Ticker/ Date\n",
    "def calculate_var(group):\n",
    "    return group['Daily_Return'].quantile(1 - .95)\n",
    "\n",
    "# Apply the function to each group\n",
    "var_df = Compared_Calcs.groupby('Ticker').apply(calculate_var).reset_index()\n",
    "\n",
    "# Create a new dataframe with this info\n",
    "var_df.columns = ['Ticker', 'VaR']\n",
    "\n",
    "# Merge the stock data and S&P 500 data based on the index\n",
    "merged_data = Compared_Calcs.merge(SPData[['SP500_Daily_Return']], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculate Beta for each Ticker\n",
    "for ticker in Compared_Calcs['Ticker'].unique():\n",
    "    if ticker != '^GSPC':\n",
    "        # Filter data for the current stock and ^GSPC\n",
    "        stock_data = merged_data[merged_data['Ticker'] == ticker]\n",
    "        \n",
    "        # Calculate the covariance between stock returns and ^GSPC returns\n",
    "        covariance = np.cov(stock_data['Daily_Return'], stock_data['SP500_Daily_Return'])[0, 1]\n",
    "        \n",
    "        # Calculate the variance of ^GSPC returns\n",
    "        variance_SP500 = np.var(stock_data['SP500_Daily_Return'])\n",
    "        \n",
    "        # Calculate Beta\n",
    "        beta = covariance / variance_SP500\n",
    "\n",
    "        # Append the data as a tuple to the list\n",
    "        beta_data.append((ticker, beta))\n",
    "        \n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "beta_df = pd.DataFrame(beta_data, columns=['Ticker', 'Beta'])\n",
    "\n",
    "#Create a variable for the average bond yield ion a given period\n",
    "Avg_5Yr_Bond_Yield = Bond_yields_filtered['CDN.AVG.3YTO5Y.AVG'].mean()\n",
    "\n",
    "#Calculate the difference between the average bond yield and each stock's yield:\n",
    "Compared_Calcs['Bond Safety Ratio'] = abs(Compared_Calcs['Yield'] - Avg_5Yr_Bond_Yield)\n",
    "\n",
    "#Reorganize Compared Calcs by Ticker\n",
    "regrouped_compared_calcs = Compared_Calcs.groupby(['Ticker', 'Date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80cc288-b626-4248-82ad-cda46d4f51e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDN.AVG.3YTO5Y.AVG</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.30</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.31</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.32</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.29</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.29</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>4.04</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>4.09</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>4.12</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>4.26</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>4.28</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CDN.AVG.3YTO5Y.AVG       Date\n",
       "0                   2.30 2018-09-21\n",
       "1                   2.31 2018-09-21\n",
       "2                   2.32 2018-09-21\n",
       "3                   2.29 2018-09-21\n",
       "4                   2.29 2018-09-21\n",
       "...                  ...        ...\n",
       "1242                4.04 2018-09-21\n",
       "1243                4.09 2018-09-21\n",
       "1244                4.12 2018-09-21\n",
       "1245                4.26 2018-09-21\n",
       "1246                4.28 2018-09-21\n",
       "\n",
       "[1247 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bond_yields_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c53d72f-f812-4c19-b01c-6279bed22d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for correlations\n",
    "correlation_matrix1 = regrouped_compared_calcs[['Bond Safety Ratio', 'Daily_Return']].corr()\n",
    "correlation_matrix2 = merged_data[['SP500_Daily_Return', 'Daily_Return']].corr()\n",
    "#Both have weak correlations | Abandoning correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c727c4e5-58fa-4173-aa21-caaf456c53ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop Null Values\n",
    "regrouped_compared_calcs.dropna()\n",
    "beta_df.dropna()\n",
    "var_df.dropna()\n",
    "stock_vol.dropna()\n",
    "SPData.dropna()\n",
    "\n",
    "# Find the top 50 highest cumulative returns while excluding 'inf' values\n",
    "top_cumulative_returns = regrouped_compared_calcs[regrouped_compared_calcs['Cumulative_Return'] != float('inf')]['Cumulative_Return'].nlargest(50).dropna()\n",
    "# Count occurrences of each 'Ticker'\n",
    "cumulative_ticker_count = top_cumulative_returns.groupby(level=0).size()\n",
    "cumulative_ticker_count = cumulative_ticker_count.sort_values(ascending=False)\n",
    "cumulative_ticker_count_list = cumulative_ticker_count.index.tolist()\n",
    "# Find the fifteen most frequent 'Ticker' values\n",
    "most_frequent_tickers_list = cumulative_ticker_count.nlargest(15).index.tolist()\n",
    "\n",
    "\n",
    "# Find the best stocks based on Beta\n",
    "lowest_risk_stocks = beta_df.sort_values(by='Beta').head(15).dropna()\n",
    "lowest_risk_stocks_list = lowest_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Find the top 15 stocks with the lowest VaR\n",
    "lowest_var_stock = var_df.nsmallest(15, 'VaR').dropna()\n",
    "lowest_var_stock_list = lowest_var_stock['Ticker'].tolist()\n",
    "\n",
    "# Get the 15 cells with the lowest values\n",
    "lowest_volatility = stock_vol.nsmallest(15).dropna()\n",
    "lowest_volatility_list = lowest_volatility.index.tolist()\n",
    "\n",
    "# Combine all the lists into one\n",
    "low_risk_analysis_list = (\n",
    "    lowest_volatility_list +\n",
    "    lowest_var_stock_list +\n",
    "    lowest_risk_stocks_list +\n",
    "    most_frequent_tickers_list\n",
    ")\n",
    "\n",
    "# Create a dictionary to count the frequency of each unique value\n",
    "lr_stock_count = {}\n",
    "for stock in low_risk_analysis_list:\n",
    "    if stock in lr_stock_count:\n",
    "        lr_stock_count[stock] += 1\n",
    "    else:\n",
    "        lr_stock_count[stock] = 1\n",
    "\n",
    "# Sort the stocks by frequency (most frequent first)\n",
    "low_risk_stocks_master_list = sorted(lr_stock_count.keys(), key=lambda x: lr_stock_count[x], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e316585-4d7e-4e95-bcfc-b7af4311a4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDN.AVG.3YTO5Y.AVG</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.30</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.31</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.32</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.29</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.29</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>4.04</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>4.09</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>4.12</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>4.26</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>4.28</td>\n",
       "      <td>2018-09-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CDN.AVG.3YTO5Y.AVG       Date\n",
       "0                   2.30 2018-09-21\n",
       "1                   2.31 2018-09-21\n",
       "2                   2.32 2018-09-21\n",
       "3                   2.29 2018-09-21\n",
       "4                   2.29 2018-09-21\n",
       "...                  ...        ...\n",
       "1242                4.04 2018-09-21\n",
       "1243                4.09 2018-09-21\n",
       "1244                4.12 2018-09-21\n",
       "1245                4.26 2018-09-21\n",
       "1246                4.28 2018-09-21\n",
       "\n",
       "[1247 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yr5_Bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ecda3c-d3b9-43a7-aad7-a3c0be5a5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 50 lowest cumulative returns while excluding 'inf' values\n",
    "worst_cumulative_returns = regrouped_compared_calcs[regrouped_compared_calcs['Cumulative_Return'] != float('inf')]['Cumulative_Return'].nsmallest(50).dropna()\n",
    "# Count occurrences of each 'Ticker'\n",
    "cumulative_ticker_count2 = worst_cumulative_returns.groupby(level=0).size()\n",
    "cumulative_ticker_count2 = cumulative_ticker_count2.sort_values(ascending=False)\n",
    "cumulative_ticker_count_list2 = cumulative_ticker_count2.index.tolist()\n",
    "# Find the fifteen most frequent 'Ticker' values\n",
    "most_frequent_tickers_list2 = cumulative_ticker_count2.nlargest(15).index.tolist()\n",
    "\n",
    "\n",
    "# Find the worst stocks based on Beta\n",
    "highest_risk_stocks = beta_df.sort_values(by='Beta').tail(15).dropna()\n",
    "highest_risk_stocks_list = highest_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Find the 15 stocks with the lowest VaR\n",
    "highest_var_stock = var_df.nlargest(15, 'VaR').dropna()\n",
    "highest_var_stock_list = highest_var_stock['Ticker'].tolist()\n",
    "\n",
    "# Get the 15 cells with the lowest volatility values\n",
    "highest_volatility = stock_vol.nlargest(15).dropna()\n",
    "highest_volatility_list = highest_volatility.index.tolist()\n",
    "\n",
    "# Combine all the lists into one\n",
    "high_risk_analysis_list = (\n",
    "    highest_volatility_list +\n",
    "    highest_var_stock_list +\n",
    "    highest_risk_stocks_list +\n",
    "    most_frequent_tickers_list2 \n",
    ")\n",
    "\n",
    "# Create a dictionary to count the frequency of each unique value\n",
    "hr_stock_count = {}\n",
    "for stock in high_risk_analysis_list:\n",
    "    if stock in hr_stock_count:\n",
    "        hr_stock_count[stock] += 1\n",
    "    else:\n",
    "        hr_stock_count[stock] = 1\n",
    "\n",
    "# Sort the stocks by frequency (most frequent first)\n",
    "high_risk_stocks_master_list = sorted(hr_stock_count.keys(), key=lambda x: hr_stock_count[x], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9c885e-b29b-4e49-ae58-252c2c0b7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable for the average risk by beta\n",
    "rsk_avg = beta_df['Beta'].mean()\n",
    "\n",
    "# Get the rows that are within an acceptable range of the average beta\n",
    "average_risk_stocks = beta_df[(beta_df['Beta'] >= rsk_avg - .1) & (beta_df['Beta'] <= rsk_avg + .1)].dropna()\n",
    "\n",
    "# Get the list of tickers for the stocks with average risk\n",
    "average_risk_stocks_list = average_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Sort the stocks in average_risk_stocks_list by proximity to the average\n",
    "average_risk_analysis_list = sorted(average_risk_stocks_list, key=lambda x: abs(beta_df.loc[beta_df['Ticker'] == x, 'Beta'].values[0] - rsk_avg))\n",
    "\n",
    "\n",
    "  \n",
    "# Set a variable for average cumulative return\n",
    "cum_avg_ret=regrouped_compared_calcs['Cumulative_Return'].groupby('Ticker').mean().dropna()\n",
    "\n",
    "# Calculate the average return\n",
    "avg_return = cum_avg_ret.mean()  \n",
    "\n",
    "# Filter the series by proximity to the average. Find the values that are within 1.0 of the average\n",
    "average_risk_returns_list1 = cum_avg_ret[(cum_avg_ret >= avg_return - 1)].index.tolist()\n",
    "average_risk_returns_list2 = cum_avg_ret[(cum_avg_ret <= avg_return + 1)].index.tolist()\n",
    "\n",
    "# Sort both lists by proximity to avg_return\n",
    "sorted_list1 = sorted(average_risk_returns_list1, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "sorted_list2 = sorted(average_risk_returns_list2, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "\n",
    "average_risk_returns_list = (sorted_list1 + sorted_list2)\n",
    "\n",
    "# Sort the stocks in average_risk_returns_list by proximity to the average risk based on cumulative returns\n",
    "average_risk_returns_master_list = sorted(average_risk_returns_list, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "\n",
    "\n",
    "\n",
    "# Creat the average Value At Risk Variable\n",
    "var_df['VaR'] = var_df['VaR'].astype(float)\n",
    "avg_var = var_df['VaR'].mean()\n",
    "\n",
    "# Calculate the absolute difference between each VaR value and the average VaR\n",
    "var_difference = var_df['VaR'].sub(avg_var).abs()\n",
    "\n",
    "# Sort the VaR values by proximity to the average VaR\n",
    "sorted_var_list = var_df['Ticker'].tolist()\n",
    "sorted_var_list.sort(key=lambda x: var_difference[var_df.loc[var_df['Ticker'] == x, 'VaR'].index[0]])\n",
    "\n",
    "# Get the top 15 values closest to the average VaR\n",
    "top_15_closest_to_avg_var = sorted_var_list[:15]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the average volatility\n",
    "avg_volatility = stock_vol.mean()\n",
    "\n",
    "# Calculate the absolute difference between each stock's volatility and the average volatility\n",
    "volatility_difference = stock_vol.sub(avg_volatility).abs()\n",
    "\n",
    "# Sort the list of stocks by proximity to the average volatility\n",
    "sorted_volatility_list = stock_vol.index.tolist()\n",
    "sorted_volatility_list.sort(key=lambda x: volatility_difference[x])\n",
    "\n",
    "# Get the top 15 stocks closest to the average volatility\n",
    "top_15_closest_to_avg_volatility = sorted_volatility_list[:15]\n",
    "\n",
    "\n",
    "\n",
    "#Combine Lists\n",
    "mid_combined_list= (top_15_closest_to_avg_var + top_15_closest_to_avg_volatility + average_risk_returns_master_list + average_risk_analysis_list)\n",
    "mid_count= Counter(mid_combined_list)\n",
    "mid_risk_stocks_master_list = [item[0] for item in sorted(mid_count.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03cef68f-f5ce-4fe5-9c96-d77d925431e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function to show a recommendaiton of 10 stocks\n",
    "def print_first_10_strings(input_list):\n",
    "    return input_list[:10]\n",
    "    \n",
    "        \n",
    "#Define Final Recommendation\n",
    "if user_risk == 'high':\n",
    "    risk_tickers = print_first_10_strings(high_risk_stocks_master_list)\n",
    "elif user_risk == 'low':\n",
    "    risk_tickers = print_first_10_strings(low_risk_stocks_master_list)\n",
    "elif user_risk == 'mid':\n",
    "    risk_tickers = print_first_10_strings(mid_risk_stocks_master_list)\n",
    "else:\n",
    "    print(\"Invalid user_risk value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9476e834-9cc9-4ca9-903e-eedc40f57153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Final Recommendations With All Data\n",
    "\n",
    "# Filter DataFrames by matching tickers\n",
    "var_df_filtered = var_df[var_df['Ticker'].isin(risk_tickers)]\n",
    "beta_df_filtered = beta_df[beta_df['Ticker'].isin(risk_tickers)]\n",
    "stock_vol_filtered = stock_vol[stock_vol.index.isin(risk_tickers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb16cab-e216-48d9-8cc1-f62b7f642593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the volatility data a dataframe\n",
    "stock_vol_filtered = stock_vol_filtered.to_frame()\n",
    "\n",
    "# Rename the Volatility Column\n",
    "stock_vol_filtered.columns = ['Volatility']\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = var_df_filtered.merge(beta_df_filtered, on='Ticker', how='left')\n",
    "\n",
    "# Now, 'merged_df' contains 'Value At Risk', 'Beta', and 'Volatility' columns with 'Ticker' as the index\n",
    "merged_df = merged_df.set_index('Ticker')\n",
    "\n",
    "# Combine 'merged_df' with 'stock_vol_filtered' by the common index 'Ticker'\n",
    "risk_analyzer = merged_df.join(stock_vol_filtered)\n",
    "\n",
    "# Rename the columns to match your desired column names\n",
    "risk_analyzer.rename(columns={'VaR': 'Value At Risk'}, inplace=True)\n",
    "\n",
    "# Create a custom sorting order based on 'risk_tickers'\n",
    "custom_order = {ticker: order for order, ticker in enumerate(risk_tickers)}\n",
    "\n",
    "\n",
    "# Use the custom order to sort the DataFrame\n",
    "risk_analyzer['sorting_order'] = risk_analyzer.index.map(custom_order)\n",
    "risk_analyzer.sort_values(by='sorting_order', inplace=True)\n",
    "risk_analyzer.drop('sorting_order', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee798a4-fab8-42c3-b9f2-9ad8d559b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize the original World_Data dataset by the final recommended list\n",
    "\n",
    "#Remove useless columns\n",
    "Useless_Columns2=['Dividends', 'Stock Splits', 'Industry_Tag', 'Country']\n",
    "Final_Stock_Display= World_Stocks.drop(columns=Useless_Columns2)\n",
    "\n",
    "#Cut the Date data down to only the daily\n",
    "Final_Stock_Display['Date'] = Final_Stock_Display['Date'].dt.date\n",
    "\n",
    "#Cut the Data down to only tickers that match the final recommended list\n",
    "Final_Stock_Display=Final_Stock_Display[Final_Stock_Display['Ticker'].isin(risk_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3940267e-6aa5-48a8-87e3-92b33b8b8e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PINS', 'TSLA', 'CROX', 'JWN', 'NVDA', 'DIS', 'MMM', 'PTON', 'ZI', 'AMD']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print Final Recommendation\n",
    "risk_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0802ebc-168a-41cc-aada-80c218cfe808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value At Risk</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PINS</th>\n",
       "      <td>-5.718185</td>\n",
       "      <td>-0.435202</td>\n",
       "      <td>4.949007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-5.125984</td>\n",
       "      <td>-0.456027</td>\n",
       "      <td>3.984862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CROX</th>\n",
       "      <td>-5.119621</td>\n",
       "      <td>-0.285014</td>\n",
       "      <td>4.407196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JWN</th>\n",
       "      <td>-4.714676</td>\n",
       "      <td>-0.897449</td>\n",
       "      <td>3.497020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-4.456210</td>\n",
       "      <td>-0.429040</td>\n",
       "      <td>3.415902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-2.681459</td>\n",
       "      <td>-0.103815</td>\n",
       "      <td>1.906029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>-2.365506</td>\n",
       "      <td>-1.011772</td>\n",
       "      <td>2.045606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTON</th>\n",
       "      <td>-7.916535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.374018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZI</th>\n",
       "      <td>-6.146155</td>\n",
       "      <td>-0.257212</td>\n",
       "      <td>4.975552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>-5.407844</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>3.932520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Value At Risk      Beta  Volatility\n",
       "Ticker                                     \n",
       "PINS        -5.718185 -0.435202    4.949007\n",
       "TSLA        -5.125984 -0.456027    3.984862\n",
       "CROX        -5.119621 -0.285014    4.407196\n",
       "JWN         -4.714676 -0.897449    3.497020\n",
       "NVDA        -4.456210 -0.429040    3.415902\n",
       "DIS         -2.681459 -0.103815    1.906029\n",
       "MMM         -2.365506 -1.011772    2.045606\n",
       "PTON        -7.916535       NaN    5.374018\n",
       "ZI          -6.146155 -0.257212    4.975552\n",
       "AMD         -5.407844  0.153465    3.932520"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Final Dataset\n",
    "risk_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3cf3aa-921a-4798-b642-ff7de16d154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.630000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>7441900.0</td>\n",
       "      <td>peloton</td>\n",
       "      <td>PTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>82.029999</td>\n",
       "      <td>83.199997</td>\n",
       "      <td>81.639999</td>\n",
       "      <td>82.559998</td>\n",
       "      <td>12715200.0</td>\n",
       "      <td>the walt disney company</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>267.040009</td>\n",
       "      <td>273.929993</td>\n",
       "      <td>262.459991</td>\n",
       "      <td>262.589996</td>\n",
       "      <td>122514600.0</td>\n",
       "      <td>tesla</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>439.029999</td>\n",
       "      <td>422.230011</td>\n",
       "      <td>422.390015</td>\n",
       "      <td>36710800.0</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.309999</td>\n",
       "      <td>26.820000</td>\n",
       "      <td>27.020000</td>\n",
       "      <td>40018600.0</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>PINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267836</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>15.790000</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>15.670000</td>\n",
       "      <td>6393800.0</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>JWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267837</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>5777300.0</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>JWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267838</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>15.760000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>16.219999</td>\n",
       "      <td>4982800.0</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>JWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267839</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16.320000</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>3604400.0</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>JWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267840</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>15.770000</td>\n",
       "      <td>15.840000</td>\n",
       "      <td>15.240000</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>5640200.0</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>JWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40566 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date        Open        High         Low       Close  \\\n",
       "0       2023-09-20    4.840000    4.910000    4.630000    4.670000   \n",
       "10      2023-09-20   82.029999   83.199997   81.639999   82.559998   \n",
       "17      2023-09-20  267.040009  273.929993  262.459991  262.589996   \n",
       "19      2023-09-20  436.000000  439.029999  422.230011  422.390015   \n",
       "27      2023-09-20   27.900000   28.309999   26.820000   27.020000   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "267836  2023-08-29   15.550000   15.790000   15.440000   15.670000   \n",
       "267837  2023-08-30   15.600000   15.870000   15.540000   15.690000   \n",
       "267838  2023-08-31   15.760000   16.250000   15.680000   16.219999   \n",
       "267839  2023-09-01   16.320000   16.530001   16.010000   16.070000   \n",
       "267840  2023-09-05   15.770000   15.840000   15.240000   15.290000   \n",
       "\n",
       "             Volume               Brand_Name Ticker  \n",
       "0         7441900.0                  peloton   PTON  \n",
       "10       12715200.0  the walt disney company    DIS  \n",
       "17      122514600.0                    tesla   TSLA  \n",
       "19       36710800.0                   nvidia   NVDA  \n",
       "27       40018600.0                pinterest   PINS  \n",
       "...             ...                      ...    ...  \n",
       "267836    6393800.0                nordstrom    JWN  \n",
       "267837    5777300.0                nordstrom    JWN  \n",
       "267838    4982800.0                nordstrom    JWN  \n",
       "267839    3604400.0                nordstrom    JWN  \n",
       "267840    5640200.0                nordstrom    JWN  \n",
       "\n",
       "[40566 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display World Data for Final Recommendations\n",
    "Final_Stock_Display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
